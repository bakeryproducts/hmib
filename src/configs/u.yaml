INPUTS: input
OUTPUTS: output

SPLIT: 0
DATA:
  DALI: false
  img_loader: 'partial(data.PngImages, suffix=".png")'
  ann_loader: 'partial(data.PngImages, suffix=".png")'
  TRAIN:
    DATASETS: [
      'hpa_train_kidney',
      'hpa_train_fixed_prostate',
      'hpa_train_largeintestine',
      'hpa_train_fixed_spleen',
      # 'hpa_train_fixed_lung',

      'hpa_extra_largeintestine',
      'hpa_extra_kidney',
      'hpa_extra_spleen',
      # 'hpa_extra_lung',
      'hpa_extra_prostate',

      'gtex_largeintestine', 
      'gtex_spleen',
      'gtex_kidney',
      'gtex_prostate',
      # 'gtex_easy_lung',

      'hubmap_kidney',
      'hubmap_largeintestine',
      ]

  VALID:
    DATASETS: [
      'hpa_valid_kidney',
      'hpa_valid_fixed_prostate',
      'hpa_valid_largeintestine',
      'hpa_valid_fixed_spleen',
      # 'hpa_valid_fixed_lung',
    ]
  VALID_HUB:
    DATASETS: ['hubmap_test_kidney', 'hubmap_test_largeintestine']
  VALID_GTEX:
    DATASETS: [
      'gtex_test_prostate',
      'gtex_test_kidney',
      'gtex_test_spleen',
      'gtex_test_largeintestine',
    ]

AUGS:
  NORM:
    MODE: 'const'
    STD: [69] 
    MEAN: [176.]
  TRAIN_RESIZE: [0]
  VALID_RESIZE: [0]
  MSR:
    scale_up: 1.0
    scale_down: 1.0
  MIXUP:
    PROB: .0
  CUTMIX:
    PROB: .0
  FMIX:
    ALPHA: 1
    REPEAT: 1
    PROB: .0

  AUG_MULTIPLICITY: 1
  # CROP: [256,256]
  # CROP: [384,384]
  # CROP: [512,512]
  # CROP: [640,640]
  CROP: [768, 768]
  # VALCROP: [512, 512]
  # VALCROP1: [512, 512]
  # VALCROP2: [512, 512]
  # VALCROP1: [960, 960]
  VALCROP1: [768, 768]
  VALCROP2: [768, 768]
  # VALCROP1: [1152, 1152]
  # VALCROP2: [1024, 1024]
  TRAIN:
    AUGS:
      # - {m : albu.RandomCrop, args : [512,512]}
      - {m : ShiftScaleRotate, kwargs : {'shift_limit': 0., 
                                         'scale_limit': [-0.5, 1.0],
                                         'rotate_limit': 40,
                                         'border_mode': 0,
                                         'value': 0,
                                         'mask_value': 0,
                                         'p': 0.8}}
      - {m : albu.RandomCrop, args : '${AUGS.CROP}'}
      - {m : albu.RandomRotate90, }
      - {m : albu.HorizontalFlip, }
      # - {m : ColorMeanShift, kwargs : {'p': 0.5}}
      - {m : HEDJitter, kwargs : {'theta': .05, 'p': 0.7}}
      - {m : ProstateDownUp, kwargs : {'scale': 4, 'p': 0.8}}
      # - {m : DomainStainer, kwargs : {'step': 100, 'domain': '"gtex"', 'p': .3,}}
      - {m : NoiseAugs, kwargs : {'p': 0.5}}
      - {m : sh.augmentation.ToTensor,}
  VALID:
    AUGS:
      - {m : ProstateDownUp, kwargs : {'scale': 4, 'p': 1.0}}
      - {m : albu.CenterCrop, args : '${AUGS.VALCROP1}'}
      - {m : sh.augmentation.ToTensor,}
  VALID_HUB:
    AUGS:
      - {m : ProstateDownUp, kwargs : {'scale': 4, 'p': 1.0}}
      - {m : albu.CenterCrop, args : '${AUGS.VALCROP2}'}
      - {m : sh.augmentation.ToTensor,}
  VALID_GTEX:
    AUGS:
      - {m : ProstateDownUp, kwargs : {'scale': 4, 'p': 1.0}}
      - {m : albu.CenterCrop, args : '${AUGS.VALCROP2}'}
      - {m : sh.augmentation.ToTensor,}

MODEL:
  ARCH: 'unet' 
  # INIT_MODEL: "/home/gsm/work/hmib/output/09-12/18-20-27_unet_convnext_large_384_in22ft1k/split_0/models/e140_t250_step_ema_0.926.pth"
  # INIT_MODEL: "/home/gsm/work/hmib/output/09-11/16-05-25_unet_convnext_large_384_in22ft1k/split_0/models/e154_t250_cmax_ema_0.9267.pth"
  INIT_MODEL: ""
  ENCODER:
    runner: 
        # _target_: encoders.encoder.create_mixt
        # _target_: encoders.encoder.create_encoder
        _target_: encoders.encoder.create_coat
        # _target_: encoders.encoder.create_swin
        _partial_: true
    # model_name: 'resnet34'
    # model_name: 'regnety_032'
    # model_name: 'coat_lite_mini'
    # model_name: 'coat_mini'
    # model_name: 'coat_lite_small'
    model_name: 'coat_lite_medium'
    # model_name: 'coatnet_1_rw_224'
    # model_name: 'swin'
    # model_name: 'mit_b3'
    # model_name: 'tf_efficientnet_b2_ns'
    # model_name: 'tf_efficientnetv2_m_in21k'
    # model_name: 'resnetv2_50x1_bitm_in21k'
    # model_name: 'convnext_small_in22ft1k'
    # model_name: 'convnext_base_in22ft1k'
    # model_name: 'convnext_base_384_in22ft1k'
    # model_name: 'convnext_large_384_in22ft1k'
    # model_name: 'dm_nfnet_f1'
    # model_name: 'convnext_tiny'
    img_size: 768
    in_chans: 4
    drop_rate: .4
    drop_path_rate: .0
    attn_drop_rate: .4

  DECODER:
    runner: 
        # _target_: decoders.decoder.create_segdec
        _target_: decoders.decoder.create_decoder
        _partial_: true
        # embedding_dim: 128
    base:
      use_bottleneck: False
      last_scale: 1
    blocks:
      - ch: 512
        e_prehook: 'torch.nn.Upsample(scale_factor=(2,2), mode="bilinear")'
      - ch: 256
        e_prehook: 'torch.nn.Upsample(scale_factor=(2,2), mode="bilinear")'
      - ch: 128
        e_prehook: 'torch.nn.Upsample(scale_factor=(2,2), mode="bilinear")'
      - ch: 64
        e_prehook: 'torch.nn.Upsample(scale_factor=(2,2), mode="bilinear")'
      - ch: 32
        e_prehook: 'torch.nn.Upsample(scale_factor=(2,2), mode="bilinear")'

  SEGHEAD:
    out_channels: 5
    kernel_size: 1

TRAIN:
  BATCH_NUM_INSTANCES: 1
  AMP: True
  GPUS: [0,1,2,3]
  NUM_WORKERS: 3
  SAVE_STEP: 20
  SCALAR_STEP: 1
  TB_STEP: 1
  START_VAL: 0
  EPOCH_COUNT: 200
  BATCH_SIZE: 8
  EARLY_EXIT: 50
  SEED: 0 # not fixed! no touching! TODO: fix this, should be hidden in config.py
  EMA: 
    ENABLE: True
    start: 0.98
    end: .995
    type: 'linear'

VALID:
  BATCH_SIZE: 4
VALID_HUB:
  BATCH_SIZE: 4
VALID_GTEX:
  BATCH_SIZE: 4

LOSS:
    - name: 'seg_dice'
      # weight: .6
      weight: .8
      LOSS:
        _target_: segmentation_models_pytorch.losses.DiceLoss
        mode: 'multilabel'
        smooth: .0

    - name: 'seg_ce'
      # weight: .4
      weight: 0.2
      LOSS:
        # _target_: torch.nn.CrossEntropyLoss
        _target_: torch.nn.BCEWithLogitsLoss
        # _target_: segmentation_models_pytorch.losses.SoftCrossEntropyLoss
        # smooth_factor: .0
    # - name: 'cls'
    #   weight: .01
    #   LOSS:
    #     _target_: torch.nn.CrossEntropyLoss
  

FEATURES:
  GRAD_CLIP: 1
  CLAMP: 10
  CLIP_MODE: 'value'
  BATCH_ACCUMULATION_STEP: 1
  USE_DS: False
  SAM:
    REDUCE: 1.
    RHO: 0.


OPTIMIZER:
  LRS: [0.000001, 0.0002, 0.00001, 1]
  # LRS: [0.000001, 0.0008, 0.0001, 1]
  # LRS: [0.000001, 0.00005, 0.00001, 1]
  # LRS: [0.000001, 0.0001, 0.00001, 1]
  # LRS: [0.0001, 0.0008, 0.0001, 1]
  # LRS: [0.0001, 0.01, 0.001, 1]
  
  FINE_LR:
    - name: 'seg_head'
      group_options:
        lr_scale: 1
        weight_decay: .005
        # weight_decay: .1

  OPT:
    _target_: torch.optim.AdamW
    # _target_: timm.optim.MADGRAD
    _partial_: true
    weight_decay: 0.001
    # weight_decay: 0.01

PARALLEL:
  DDP: True


_postfix : ${MODEL.ARCH}_${MODEL.ENCODER.model_name}
hydra:
  run:
    dir: ./output/${now:%m-%d}/${now:%H-%M-%S}_${_postfix}
  sweep:
    dir : ./output/${now:%m-%d}/${now:%H-%M-%S}_SWEEP
    subdir: J${hydra.job.num}_${_postfix}

defaults: 
    - PARALLEL: _parallel
    - VALID: _valid
    - FEATURES.SAM: _sam
    - AUGS.MIXUP: _mixup
    - _self_
    # - DATA: datasets_1.2
    - DATA: datasets_1.2_rate
    # - DATA: datasets_1.0_rate
