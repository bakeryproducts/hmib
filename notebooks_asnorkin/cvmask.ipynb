{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import sys\n",
    "from shutil import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from evaluate import dice\n",
    "from mask_utils import rle_decode, rle_encode\n",
    "\n",
    "\n",
    "DUMMY_RLE = \"\"\n",
    "DATA_SOURCES = {'HPA'}\n",
    "ORGANS = {'lung'}\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "lung_filter_dir = \"../input/hmib/lung_filter/\"\n",
    "images_dir = \"../input/hmib/train_images/\"\n",
    "df_file = \"../input/hmib/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8508d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lung_df = df[df.organ == \"lung\"]\n",
    "# for row in tqdm(lung_df.itertuples(), total=len(lung_df)):\n",
    "#     name = f\"{row.id}.tiff\"\n",
    "#     src = osp.join(images_dir, name)\n",
    "#     dst = osp.join(lung_filter_dir, name)\n",
    "#     copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4455d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# lung_df = df[df.organ == \"lung\"]\n",
    "\n",
    "# train_indices, val_indices = train_test_split(lung_df.index.values, test_size=0.2, random_state=2022)\n",
    "# lung_df.loc[train_indices, \"split\"] = \"train\"\n",
    "# lung_df.loc[val_indices, \"split\"] = \"val\"\n",
    "# lung_df[[\"id\", \"split\"]].rename(columns={\"id\": \"image_name\"}).to_csv(osp.join(lung_filter_dir, \"splits.csv\"), index=False)\n",
    "\n",
    "# # Counter(map(tuple, lung_df[[\"age\", \"sex\"]].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# DST_SIZE = (768, 768)\n",
    "\n",
    "# for image_file in tqdm(Path(lung_filter_dir).glob(\"*.tiff\")):\n",
    "#     image = load_tiff(image_file).transpose((1, 2, 0))\n",
    "\n",
    "#     anno_file = osp.splitext(image_file)[0] + \".json\"\n",
    "#     mask = load_abno(anno_file, image.shape[:2])\n",
    "    \n",
    "#     image_dst = cv2.resize(image, DST_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "#     mask_dst = cv2.resize(mask, DST_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "#     name = osp.splitext(osp.basename(image_file))[0]\n",
    "    \n",
    "#     image_name = f\"{name}_image.png\"\n",
    "#     cv2.imwrite(osp.join(lung_filter_dir, image_name), image_dst)\n",
    "    \n",
    "#     mask_name = f\"{name}_mask.png\"\n",
    "#     cv2.imwrite(osp.join(lung_filter_dir, mask_name), mask_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32990b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, mask=None, mask_abno=None, title=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    if mask is not None:\n",
    "        plt.imshow(1.0 - mask, alpha=0.3)\n",
    "    if mask_abno is not None:\n",
    "        plt.imshow(1.0 - mask_abno, alpha=0.15)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def load_abno(anno_file, shape):\n",
    "    if not osp.exists(anno_file):\n",
    "        return np.zeros(shape)\n",
    "    \n",
    "    with open(anno_file) as inpf:\n",
    "        anno = json.load(inpf)\n",
    "\n",
    "    anno_mask = np.zeros(shape)\n",
    "    for raw_poly in anno:\n",
    "        poly = Polygon(raw_poly[\"geometry\"][\"coordinates\"][0])\n",
    "        poly_mask = rio.features.rasterize([poly], out_shape=shape)\n",
    "        anno_mask = np.maximum(anno_mask, poly_mask)\n",
    "\n",
    "    if anno_mask.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    return anno_mask\n",
    "\n",
    "\n",
    "def load_tiff(p):\n",
    "    return rio.open(str(p)).read()\n",
    "\n",
    "\n",
    "def grad(img, kernel=5):\n",
    "    kernel = np.ones((kernel, kernel),np.uint8)\n",
    "    gx = cv2.morphologyEx(img.mean(2) / img.max(), cv2.MORPH_GRADIENT, kernel)\n",
    "    return gx\n",
    "\n",
    "\n",
    "def fill_holes(mask):\n",
    "    des = cv2.bitwise_not(mask)\n",
    "    contour,hier = cv2.findContours(des,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contour:\n",
    "        cv2.drawContours(des,[cnt],0,255,-1)\n",
    "\n",
    "    return cv2.bitwise_not(des)\n",
    "\n",
    "\n",
    "def cvmask(name, min_area=40**2, max_area=220**2, bf_size=2, bf_min_count=3):\n",
    "    image = load_tiff(name)\n",
    "    \n",
    "    #C,H,W = image.shape\n",
    "    #means.append(H)\n",
    "    #image = image[0]#.mean(0)\n",
    "#     image = image[:,1000:2000, 1000:2000]\n",
    "    \n",
    "    gx = grad(image.transpose(1,2,0), 13)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    gx = cv2.morphologyEx(gx, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    gx = cv2.blur(gx, (5,5))\n",
    "    \n",
    "    num, *(imask, stats, centr) = cv2.connectedComponentsWithStats((gx<.1).astype(np.uint8))\n",
    "    areas = stats[:, 4]\n",
    "\n",
    "    idxs = np.argsort(areas)[::-1]\n",
    "    iareas = areas[idxs]\n",
    "\n",
    "    #l, h = np.percentile(areas, 1), np.percentile(areas, 99)\n",
    "    mask = (iareas > min_area) & (iareas < max_area) #& (iareas > l) & (iareas < h)\n",
    "\n",
    "    # Filter border contours\n",
    "    border_filter = np.zeros_like(imask)\n",
    "    border_filter[:bf_size] = 1\n",
    "    border_filter[-bf_size:] = 1\n",
    "    border_filter[:, :bf_size] = 1\n",
    "    border_filter[:, -bf_size:] = 1\n",
    "    for iid, icount in zip(*np.unique(imask * border_filter, return_counts=True)):\n",
    "        if iid != 0 and icount >= bf_min_count:\n",
    "            mask[idxs == iid] = False\n",
    "\n",
    "    instances = idxs[mask]\n",
    "    mm = [imask == i for i in instances if i != 0]\n",
    "    if len(mm) > 0:\n",
    "        mm = np.stack(mm).sum(0)[None]  #.astype(np.uint8)\n",
    "    else:\n",
    "        mm = np.zeros_like(image)[0:1]\n",
    "\n",
    "    return mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe9ad3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_file)\n",
    "result = []\n",
    "dices = []\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Inference\"):\n",
    "    rle = DUMMY_RLE\n",
    "    organ = row.organ\n",
    "    \n",
    "    if row.data_source in DATA_SOURCES and organ in ORGANS:\n",
    "        image_file = osp.join(images_dir, f\"{row.id}.tiff\")\n",
    "        \n",
    "        mask = cvmask(image_file)\n",
    "        mask = cv2.dilate(mask[0].astype(float), kernel=np.ones((5, 5)), iterations=3)[None]\n",
    "        mask = mask[0]\n",
    "        \n",
    "        rle = rle_encode((mask > THRESHOLD).astype(np.uint8))\n",
    "        \n",
    "        decoded_mask = rle_decode(rle, mask.shape)\n",
    "        decoded_gt = rle_decode(row.rle, mask.shape)\n",
    "        img = cv2.imread(image_file)  #[1000:2000, 1000:2000]\n",
    "        \n",
    "        anno_file = osp.join(lung_filter_dir, f\"{row.id}|MANUAL.json\")\n",
    "        abno_mask = load_anno(anno_file, img.shape[:2])\n",
    "        show(img, decoded_mask, abno_mask)\n",
    "        \n",
    "        dices.append((row.id, dice(decoded_gt, decoded_mask)))\n",
    "\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.hist(mask.flatten(), bins=100)\n",
    "#         plt.grid()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a069b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dices, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([d for _, d in dices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50933f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubmap_env",
   "language": "python",
   "name": "hubmap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
