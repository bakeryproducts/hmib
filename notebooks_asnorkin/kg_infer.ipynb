{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc064ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations.augmentations.geometric.functional as AGF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                       Change only this                            #\n",
    "#####################################################################\n",
    "EXPERIMENT = \"unet_resnet34\"\n",
    "CKPT = \"e28_t100_cmax_ema_0.746.pth\"\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "BLOCK_SIZE = 512\n",
    "NETWORK_SCALE = 1. / 3\n",
    "# TODO:\n",
    "# HUBMAP_SCALE = 1.0\n",
    "# HPA_SCALE = 1.0\n",
    "PAD_RATIO = 0.25\n",
    "BATCH_SIZE = 6\n",
    "THRESHOLD = 0.5\n",
    "TTA = False\n",
    "\n",
    "DATA_SOURCES = {'Hubmap', 'HPA'}\n",
    "# DATA_SOURCES = {'HPA'}\n",
    "ORGANS = {'kidney', 'prostate', 'largeintestine', 'spleen', 'lung'}\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                         Do not change                             #\n",
    "#####################################################################\n",
    "HMIB_MODELS_DIR = \"/home/ubuntu/asnorkin/background_matting/robustvideomatting/tmp/hmib/output/\"\n",
    "EXP_DIR = osp.join(HMIB_MODELS_DIR, EXPERIMENT)\n",
    "SRC_DIR = osp.join(EXP_DIR, \"src\")\n",
    "\n",
    "# Imports from src\n",
    "sys.path.append(SRC_DIR)\n",
    "import network  # From src\n",
    "from infer import init_model, norm_2d\n",
    "\n",
    "\n",
    "# Config and Model\n",
    "CONFIG_FILE = osp.join(SRC_DIR, \"configs/u.yaml\")\n",
    "MODEL_FILE = osp.join(EXP_DIR, \"split_0/models\", CKPT)\n",
    "\n",
    "\n",
    "# Images and output paths\n",
    "DATA_DIR = \"/home/ubuntu/asnorkin/background_matting/robustvideomatting/tmp/hmib/input/hmib/\"\n",
    "TEST_IMAGES_DIR = osp.join(DATA_DIR, \"test_images\")\n",
    "TRAIN_IMAGES_DIR = osp.join(DATA_DIR, \"train_images\")\n",
    "TEST_CSV_FILE = osp.join(DATA_DIR, \"test.csv\")\n",
    "TRAIN_CSV_FILE = osp.join(DATA_DIR, \"train.csv\")\n",
    "OUTPUT_FILE = \"/kaggle/working/submission.csv\"\n",
    "DUMMY_RLE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579a31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#                             Model                                 #\n",
    "#####################################################################\n",
    "def preprocess(batch):\n",
    "    \"\"\"Preprocessing\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    batch: np.array of shape (batch, height, width, channels); batch of raw images.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X: torch.Tensor of shape (batch, channels, height, width); batch of preprocessed images.\n",
    "    \"\"\"\n",
    "    X = torch.from_numpy(batch.transpose((0, 3, 1, 2))).float().to(DEVICE)\n",
    "    X, mean, std = norm_2d(X, mean=cfg.AUGS.MEAN, std=cfg.AUGS.STD)\n",
    "    return X\n",
    "\n",
    "\n",
    "def tta_4rot90_encode(batch):\n",
    "    return torch.concat([\n",
    "        torch.rot90(batch, k=k, dims=[2, 3]) for k in range(4)\n",
    "    ])\n",
    "\n",
    "\n",
    "def tta_4rot90_decode(y):\n",
    "    bs = y.shape[0] // 4\n",
    "    \n",
    "    y_ori = y[:bs]\n",
    "    y_90 = y[bs: 2 * bs]\n",
    "    y_180 = y[2 * bs: 3 * bs]\n",
    "    y_270 = y[3 * bs:]\n",
    "    \n",
    "    return torch.stack([\n",
    "        torch.rot90(yi, k=-i, dims=[2, 3]) \n",
    "        for i, yi in enumerate([y_ori, y_90, y_180, y_270])\n",
    "    ]).mean(dim=0)\n",
    "\n",
    "\n",
    "def tta_encode(batch):\n",
    "    return torch.concat([\n",
    "        tta_4rot90_encode(batch),\n",
    "        tta_4rot90_encode(torch.flip(batch, dims=(2,))),\n",
    "    ])\n",
    "\n",
    "\n",
    "def tta_decode(y):\n",
    "    bs = y.shape[0] // 8\n",
    "    \n",
    "    return torch.stack([\n",
    "        tta_4rot90_decode(y[:bs * 4]),\n",
    "        tta_4rot90_decode(torch.flip(y[bs * 4:], dims=(2,))),\n",
    "    ]).mean(dim=0)\n",
    "\n",
    "\n",
    "def infer(batch, model, threshold=None, sigmoid=True, tta=False):\n",
    "    \"\"\"Inference\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    batch: torch.Tensor of shape (batch, channels, height, width)\n",
    "        Batch of preprocessed images\n",
    "    model: torch.nn.Module\n",
    "        Model\n",
    "    threshold: float\n",
    "        Confidence threshold\n",
    "    sigmoid: bool\n",
    "        Apply sigmoid or not\n",
    "    tta: bool\n",
    "        Apply 4 flips TTA or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    yb: np.array of shape (batch, height, width, 1)\n",
    "        Batch masks\n",
    "    \"\"\"\n",
    "    ori_batch_size = batch.shape[0]\n",
    "    \n",
    "    # Extend batch\n",
    "    if tta:\n",
    "        batch = tta_encode(batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            batch_pred = model({\"xb\": batch})\n",
    "        \n",
    "    yb = batch_pred[\"yb\"].float()\n",
    "    \n",
    "    # Average predictions\n",
    "    if tta:\n",
    "        yb = tta_decode(yb)\n",
    "    \n",
    "    if sigmoid:\n",
    "        yb.sigmoid_()\n",
    "    \n",
    "    if threshold is not None:\n",
    "        yb = (yb > threshold)\n",
    "    else:\n",
    "        pass\n",
    "#         yb = (yb * 255)\n",
    "\n",
    "    yb = yb.cpu().numpy()\n",
    "    yb = yb.transpose((0, 2, 3, 1))\n",
    "    yb = yb.astype(np.uint8)\n",
    "        \n",
    "    return yb\n",
    "\n",
    "\n",
    "def get_inferer(model, **inferer_kw):\n",
    "\n",
    "    def inferer(batch):\n",
    "        return infer(\n",
    "            preprocess(batch), \n",
    "            model=model, \n",
    "            **inferer_kw,\n",
    "        )\n",
    "    \n",
    "    return inferer\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                            Blocks                                 #\n",
    "#####################################################################\n",
    "def generate_block_coords(H, W, block_size):\n",
    "    h,w = block_size\n",
    "    nYBlocks = (int)((H + h - 1) / h)\n",
    "    nXBlocks = (int)((W + w - 1) / w)\n",
    "    \n",
    "    for X in range(nXBlocks):\n",
    "        cx = X * h\n",
    "        for Y in range(nYBlocks):\n",
    "            cy = Y * w\n",
    "            yield cy, cx, h, w\n",
    "            \n",
    "            \n",
    "def pad_block(y, x, h, w, pad): \n",
    "    return np.array([y - pad, x - pad, h + 2 * pad, w + 2 * pad])\n",
    "\n",
    "\n",
    "def crop(src, y, x, h, w): \n",
    "    return src[..., y: y + h, x: x + w]\n",
    "\n",
    "\n",
    "def paste(src, block, y, x, h, w):\n",
    "    src[..., y: y + h, x: x + w] = block\n",
    "    \n",
    "    \n",
    "def paste_crop(src, part, block_cd, pad):\n",
    "    H, W = src.shape[-2:]\n",
    "    y, x, h, w = block_cd\n",
    "    h, w = min(h, H - y), min(w, W - x)  \n",
    "    part = crop(part, pad, pad, h, w)\n",
    "    paste(src, part, *block_cd)\n",
    "    \n",
    "    \n",
    "# TODO: check in public notebooks\n",
    "def mask2rle(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def rescale(batch_img, scale):\n",
    "    return torch.nn.functional.interpolate(\n",
    "        batch_img, \n",
    "        scale_factor=(scale, scale), \n",
    "        mode='bilinear', \n",
    "        align_corners=False\n",
    "    )\n",
    "\n",
    "            \n",
    "#####################################################################\n",
    "#                      TiffReader class                             #\n",
    "#####################################################################\n",
    "class TiffReader:\n",
    "    \"\"\"Reads tiff files.\n",
    "\n",
    "    If subdatasets are available, then use them, otherwise just handle as usual.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_to_tiff_file: str):\n",
    "        self.ds = rio.open(path_to_tiff_file)\n",
    "        self.subds_list = [rio.open(subds_path) for subds_path in self.ds.subdatasets]\n",
    "\n",
    "    def read(self, window=None, boundless=True):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        output: np.array of shape (height, width, channels)\n",
    "            Result image\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: rescale window\n",
    "        ds_kwargs = {}\n",
    "        if window is not None: \n",
    "            ds_kwargs.update({'window': window, 'boundless': boundless})\n",
    "            \n",
    "        if self.is_subsets_avail:\n",
    "            output = np.vstack(\n",
    "                [ds.read(**ds_kwargs) for ds in self.subds_list])\n",
    "        else:\n",
    "            output = self.ds.read(**ds_kwargs)\n",
    "            \n",
    "        output = output.transpose((1, 2, 0))\n",
    "        return output\n",
    "    \n",
    "    def read_block(self, y, x, h, w, boundless=True):\n",
    "        return self.read(\n",
    "            window=((y, y + h), (x, x + w)), \n",
    "            boundless=boundless\n",
    "        )\n",
    "    \n",
    "    def read_batch(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @property\n",
    "    def is_subsets_avail(self):\n",
    "        return len(self.subds_list) > 0\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        if self.is_subsets_avail:\n",
    "            return self.subds_list[0].shape\n",
    "        else:\n",
    "            return self.ds.shape\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.ds\n",
    "        del self.subds_list\n",
    "    \n",
    "    def close(self):\n",
    "        self.ds.close()\n",
    "        for subds in self.subds_list:\n",
    "            subds.close()\n",
    "            \n",
    "\n",
    "#####################################################################\n",
    "#                   BatchedTiffReader class                         #\n",
    "#####################################################################\n",
    "class BatchedTiffReader(TiffReader):\n",
    "    def __init__(\n",
    "        self, \n",
    "        path_to_tiff_file: str, \n",
    "        block_size: int, \n",
    "        network_scale: float, \n",
    "        pad_ratio: float, \n",
    "        batch_size: int\n",
    "    ):\n",
    "        super().__init__(path_to_tiff_file)\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.network_scale = network_scale\n",
    "        self.pad_ratio = pad_ratio\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        H, W = self.shape\n",
    "        scaled_block_size = self.scaled_block_size\n",
    "        self.blocks_coords = list(generate_block_coords(\n",
    "            H, W, block_size=(scaled_block_size, scaled_block_size)\n",
    "        ))\n",
    "        self.next_block = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.total_blocks / self.batch_size))\n",
    "\n",
    "    @property\n",
    "    def scaled_block_size(self):\n",
    "        return int(round(self.block_size / self.network_scale))\n",
    "\n",
    "    @property\n",
    "    def pad_size(self):\n",
    "        return int(round(self.block_size * self.pad_ratio))\n",
    "\n",
    "    @property\n",
    "    def scaled_pad_size(self):\n",
    "        return int(round(self.scaled_block_size * self.pad_ratio))\n",
    "\n",
    "    @property\n",
    "    def total_blocks(self):\n",
    "        return len(self.blocks_coords)\n",
    "\n",
    "    @property\n",
    "    def inv_network_scale(self):\n",
    "        return 1.0 / self.network_scale\n",
    "\n",
    "    def has_next_block(self):\n",
    "        return self.next_block < len(self.blocks_coords)\n",
    "\n",
    "    def read_batch(self):\n",
    "        if not self.has_next_block():\n",
    "            return None\n",
    "\n",
    "        batch_blocks, batch_coords = [], []\n",
    "        for i in range(self.batch_size):\n",
    "            if not self.has_next_block():\n",
    "                break\n",
    "\n",
    "            block_cd = self.blocks_coords[self.next_block]\n",
    "            padded_block_cd = pad_block(*block_cd, self.scaled_pad_size)\n",
    "            block = self.read_block(*padded_block_cd)\n",
    "            block = AGF.scale(block, self.network_scale)\n",
    "            batch_blocks.append(block)\n",
    "            batch_coords.append(block_cd)\n",
    "\n",
    "            self.next_block += 1\n",
    "\n",
    "        return np.stack(batch_blocks), np.stack(batch_coords)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.read_batch, None)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                       Image Inference                             #\n",
    "#####################################################################\n",
    "def infer_image(image_file, inferer, debug=False):\n",
    "    # Create Batched Reader\n",
    "    image_reader = BatchedTiffReader(\n",
    "        image_file, \n",
    "        block_size=BLOCK_SIZE, \n",
    "        network_scale=NETWORK_SCALE, \n",
    "        pad_ratio=PAD_RATIO, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    H, W = image_reader.shape\n",
    "\n",
    "    # Infer batch by batch\n",
    "    mask = np.zeros((1, H, W)).astype(np.float32 if debug else bool)\n",
    "    for batch_blocks, batch_coords in image_reader:\n",
    "        batch_masks = inferer(batch_blocks)\n",
    "        for block_mask, block_cd in zip(batch_masks, batch_coords):\n",
    "            block_mask = AGF.scale(block_mask, image_reader.inv_network_scale)\n",
    "            block_mask = block_mask.transpose((2, 0, 1))\n",
    "            paste_crop(mask, block_mask, block_cd, image_reader.scaled_pad_size)\n",
    "\n",
    "    # Close the Reader\n",
    "    image_reader.close()\n",
    "\n",
    "    # Build the result\n",
    "    return mask if debug else mask2rle(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c33732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "cfg = OmegaConf.load(CONFIG_FILE)\n",
    "cfg.MODEL.ENCODER.pretrained = False\n",
    "\n",
    "model = init_model(cfg, MODEL_FILE, network, to_gpu=(DEVICE == \"cuda\"))\n",
    "inferer = get_inferer(model=model, threshold=THRESHOLD, tta=TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "438364f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 88/88 [00:52<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "SPLIT = 0\n",
    "\n",
    "images_dir = TRAIN_IMAGES_DIR\n",
    "df = pd.read_csv(TRAIN_CSV_FILE)\n",
    "\n",
    "if SPLIT is not None:\n",
    "    split_indices = pd.read_csv(f\"../input/splits/{SPLIT}.csv\", header=None)\n",
    "    split_indices = split_indices.iloc[:, 0].values\n",
    "    df = df[df.index.isin(split_indices)]\n",
    "\n",
    "result = []\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"Inference\"):\n",
    "    rle = DUMMY_RLE\n",
    "    if row.data_source in DATA_SOURCES and row.organ in ORGANS:\n",
    "        image_file = osp.join(images_dir, f\"{row.id}.tiff\")\n",
    "        rle = infer_image(image_file, inferer)\n",
    "        \n",
    "    df.loc[row.Index, \"rle_pred\"] = rle\n",
    "\n",
    "    result.append({\n",
    "        \"id\": row.id,\n",
    "        \"rle\": rle\n",
    "    })\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "# result.to_csv(OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0e2ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_dice(row):\n",
    "    mask_gt = rle2mask(row.rle, shape=(row.img_height, row.img_width))\n",
    "    mask_pred = rle2mask(row.rle_pred, shape=(row.img_height, row.img_width))\n",
    "    return dice(mask_gt, mask_pred)\n",
    "\n",
    "\n",
    "def dice(mask_gt, mask_pred, eps=1e-6):\n",
    "    intersection = mask_gt * mask_pred\n",
    "    return (2 * intersection.sum() + eps) / (mask_gt.sum() + mask_pred.sum() + eps)\n",
    "\n",
    "\n",
    "def rle2mask(rle, shape):\n",
    "    seq = rle.split()\n",
    "    \n",
    "    starts = np.array(list(map(int, seq[0::2])))\n",
    "    lengths = np.array(list(map(int, seq[1::2])))\n",
    "    assert len(starts) == len(lengths)\n",
    "    \n",
    "    ends = starts + lengths\n",
    "    img = np.zeros((np.product(shape),), dtype=np.uint8)\n",
    "    for begin, end in zip(starts, ends):\n",
    "        img[begin:end] = 1\n",
    "\n",
    "    img.shape = shape\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7dc7aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    df.loc[row.Index, \"dice\"] = row_dice(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "193c20e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353670442811283"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1a44fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPA dice: 0.735\n",
      "Hubmap dice: nan\n"
     ]
    }
   ],
   "source": [
    "for source in DATA_SOURCES:\n",
    "    source_dice = df[df.data_source == source].dice.mean()\n",
    "    print(f\"{source} dice: {source_dice:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f53e57a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spleen dice: 0.716\n",
      "lung dice: 0.142\n",
      "prostate dice: 0.818\n",
      "kidney dice: 0.933\n",
      "largeintestine dice: 0.892\n"
     ]
    }
   ],
   "source": [
    "for organ in ORGANS:\n",
    "    organ_dice = df[df.organ == organ].dice.mean()\n",
    "    print(f\"{organ} dice: {organ_dice:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8f7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm_env",
   "language": "python",
   "name": "hm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
